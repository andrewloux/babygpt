{"id":"babygpt-04s","title":"1.1.5 Gap: Why telescoping cancellation works conceptually","description":"Line ~463-465: Cancellation is SHOWN but not EXPLAINED. Is it luck? Feature of decomposition? FIX: Add explanation that telescoping works because we're decomposing a joint probability into a product of conditionals. Each P(x_i | x_\u003ci) appears once in numerator (for position i) and once in denominator (as part of x_\u003ci+1 context). The structure guarantees cancellation — it's not coincidence.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:48:08.603807-05:00","updated_at":"2025-12-20T21:05:37.442196-05:00","closed_at":"2025-12-20T21:05:37.442196-05:00","close_reason":"FIXED: Points at actual numbers in example - 'Look at the 5: denominator of 5/6 and numerator of 4/5. Both are C(the).' Shows WHY they cancel, not just that they do."}
{"id":"babygpt-0gn","title":"2.3 Gap: Why THIS definition of similarity","description":"Line ~364-367: 'Close if they predict similar next characters' presented as obvious. WHY this definition? Why not semantic similarity? FIX: Add justification: we're building a LANGUAGE MODEL, not a thesaurus. The model's job is to predict next tokens. Two tokens are 'the same' for our purposes if they make the same predictions. Semantic similarity is irrelevant — predictive role is everything.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:49:27.539968-05:00","updated_at":"2025-12-20T21:29:45.991283-05:00","closed_at":"2025-12-20T21:29:45.991283-05:00","close_reason":"FIXED: Added justification in Section 2.3 explaining why similarity is defined by predictive role (language model purpose) rather than semantic similarity. Brief, first-principles explanation pointing at the model's job."}
{"id":"babygpt-0jb","title":"2.4 Gap: HOW reusability solves capacity","description":"Line ~546-548: Claims 27^8 contexts can't be stored but embeddings work because 'reusable'. HOW? Math not shown. FIX: Add explicit math. Lookup table: 27^8 × 27 = 282 trillion params. Embedding approach: 27 × D embeddings + D × 27 output weights. For D=64: 27×64 + 64×27 = 3,456 params. That's 80 billion times smaller. The compression comes from SHARING embeddings across contexts.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:50:00.813514-05:00","updated_at":"2025-12-20T21:39:52.578793-05:00","closed_at":"2025-12-20T21:39:52.578793-05:00","close_reason":"Fixed: Added explicit math - 282 trillion vs 3,456 params"}
{"id":"babygpt-0ky","title":"2.13 Validate Ch2 invariant: Softmax converts logits to probs","description":"AUDIT: Read section 2.7, verify softmax formula and role (converts logits to probs that sum to 1). IF missing: add formula. IF role unclear: add explicit 'why softmax?' callout.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:12:20.801913-05:00","updated_at":"2025-12-20T19:47:18.814628-05:00","closed_at":"2025-12-20T19:47:18.814628-05:00","close_reason":"Closed"}
{"id":"babygpt-0la","title":"1.4 Validate Ch1 map waypoint 1.3.2 Free Lunch","description":"AUDIT: Navigate to 1.3.2, verify 'One block of text becomes thousands of training targets' is accurate. IF mismatch: update description. Check if the 'free lunch' concept is actually explained.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:11:23.742655-05:00","updated_at":"2025-12-20T19:31:19.283738-05:00","closed_at":"2025-12-20T19:31:19.283738-05:00","close_reason":"Closed"}
{"id":"babygpt-0ok","title":"PHASE 2: Invariant Validation","description":"Validate all chapter invariants are properly established in content (14 issues)","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-20T19:10:58.324938-05:00","updated_at":"2025-12-20T20:30:20.161825-05:00","closed_at":"2025-12-20T20:30:20.161825-05:00","close_reason":"All invariant validation issues resolved. Invariants properly established and consistently referenced across both chapters."}
{"id":"babygpt-0q9","title":"8.5 Gap audit: perplexity","description":"AUDIT: Perplexity appears in 1.1.7.2 and 1.3.1. Verify defined before first use with formula. IF gap: create ticket to add perplexity definition section.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:16:47.075429-05:00","updated_at":"2025-12-20T19:56:22.071385-05:00","closed_at":"2025-12-20T19:56:22.071385-05:00","close_reason":"Closed","comments":[{"id":11,"issue_id":"babygpt-0q9","author":"andrewlouis","text":"NEEDS_FIX: Perplexity first used at line 757 (section 1.1.7.1) without definition. Formula appears later at line 903 in Exercise 1.1. Need to add perplexity definition (perplexity = 2^H where H is cross-entropy) before line 757, or add a forward reference callout.","created_at":"2025-12-21T00:48:19Z"}]}
{"id":"babygpt-0w0","title":"CSS: Consolidate border-radius to design tokens","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T23:18:16.703776-05:00","updated_at":"2025-12-20T23:32:31.882141-05:00","closed_at":"2025-12-20T23:32:31.882141-05:00","close_reason":"Closed"}
{"id":"babygpt-167","title":"NeuralTrainingDemo: Polish sweep","description":"Audit NeuralTrainingDemo for:\n- Theme consistency (colors, fonts, spacing)\n- Visual polish (training animation, weight updates)\n- Accessibility (aria labels, keyboard nav)\n- Mobile responsiveness\n- Document patterns to replicate in other vizzes","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T22:54:07.042608-05:00","updated_at":"2025-12-20T22:54:58.05393-05:00","closed_at":"2025-12-20T22:54:58.05393-05:00","close_reason":"Wrong - this IS a gold standard (Dec 19), not needing sweep"}
{"id":"babygpt-1l3","title":"Gradient Tugs: Add Karpathy-style code walkthrough","description":"GradientTraceDemo: Two-panel (code left, output right). Tiny example: vocab=[q,u,a], dim=4, context=q, target=u. 8 steps: lookup → scores → softmax → loss → centroid → gradient → update → verify. Show actual numbers. Controls: Next/Prev/Reset. Key: watch E[q] move toward E[u] with real coordinates.","status":"closed","issue_type":"feature","created_at":"2025-12-20T22:13:13.851354-05:00","updated_at":"2025-12-20T22:28:05.909701-05:00","closed_at":"2025-12-20T22:28:05.909701-05:00","close_reason":"Implemented GradientTraceDemo: 8-step Karpathy-style code walkthrough showing actual numbers (q-u-a vocab, 4D embeddings). Each step shows code and computed output. Demonstrates lookup, dot product scores, softmax, loss, centroid, gradient, update, and verification that P(u) increased."}
{"id":"babygpt-1qr","title":"2.3 Gap: Why dot product, not Euclidean or KL","description":"Line ~380-382: Dot product presented as THE similarity metric. Why not Euclidean distance or KL divergence? FIX: Add Callout explaining the choice. Dot product: (1) differentiable, (2) distributes over addition (crucial for gradients), (3) computation is just multiply-accumulate (fast on GPUs). Euclidean works but gradients are messier. KL requires logs. Dot product is the engineering sweet spot.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:49:34.701876-05:00","updated_at":"2025-12-20T21:30:53.858216-05:00","closed_at":"2025-12-20T21:30:53.858216-05:00","close_reason":"FIXED: Added engineering justification for dot product in Section 2.6. Explains three constraints: (1) differentiability (clean gradients), (2) distributes over addition (crucial for gradient flow/attention), (3) GPU-efficient (multiply-accumulate primitive). Addresses why not Euclidean (messier gradients, doesn't compose) or KL divergence (requires logs)."}
{"id":"babygpt-20f","title":"5.4 Validate SectionLinks in Ch2 exercises","description":"AUDIT: Lines 1804, 1825, 1836, 1876 in Ch2 exercises. Verify each SectionLink to 2.2, 2.3, 2.6 points to correct section. IF any broken: fix. IF any inaccurate: update link text.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:14:40.221003-05:00","updated_at":"2025-12-20T20:26:48.405294-05:00","closed_at":"2025-12-20T20:26:48.405294-05:00","close_reason":"FIXED: Corrected 2 SectionLinks in Ch2 exercises (lines 1845, 1856) from 2.2 to 2.3 - the CharacterClusterViz (similarity panel, corpus editor) is in Section 2.3","comments":[{"id":13,"issue_id":"babygpt-20f","author":"andrewlouis","text":"NEEDS_FIX: Line 1825 has incorrect SectionLink - says 'cosine similarity (in the Section 2.2 panel)' but CharacterClusterViz (which shows cosine similarity) is in Section 2.3, not 2.2. Should be: 'cosine similarity (in the \u003cSectionLink to=\"2.3\"\u003eSection 2.3\u003c/SectionLink\u003e panel)'. Other SectionLinks at lines 1804, 1825 (second one to 2.6), and 1876 are correct.","created_at":"2025-12-21T01:03:52Z"}]}
{"id":"babygpt-2a3","title":"PHASE 11: Explanatory Gap Remediation","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-20T20:47:16.994855-05:00","updated_at":"2025-12-20T20:47:16.994855-05:00"}
{"id":"babygpt-2ez","title":"1.6 Validate Ch1 map waypoint 1.7 What's Next","description":"AUDIT: Navigate to 1.7, verify 'map not phone book' description. IF mismatch: update. Check if section properly foreshadows Ch2 without premature detail.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:11:24.327936-05:00","updated_at":"2025-12-20T19:31:19.841105-05:00","closed_at":"2025-12-20T19:31:19.841105-05:00","close_reason":"Closed"}
{"id":"babygpt-2ml","title":"PHASE 8: Gap Detection","description":"Find concepts used before defined (7 issues)","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-20T19:11:00.094835-05:00","updated_at":"2025-12-20T20:30:36.701205-05:00","closed_at":"2025-12-20T20:30:36.701205-05:00","close_reason":"Gap detection audit complete. Fixed: perplexity definition. Other concepts properly introduced before use."}
{"id":"babygpt-2ox","title":"SoftmaxSimplexViz: Polish sweep","description":"Sweep SoftmaxSimplexViz for:\n- Theme consistency (colors, fonts, spacing match existing vizzes)\n- Visual polish (gradients, transitions, hover states, ambient glow?)\n- Accessibility (aria labels, keyboard nav)\n- Mobile responsiveness\n- Trail animation smoothness\n- Compare against GradientDescentViz/CrossEntropyViz as gold standard","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T22:51:31.167963-05:00","updated_at":"2025-12-20T22:52:16.12619-05:00","closed_at":"2025-12-20T22:52:16.12619-05:00","close_reason":"Recreating with expanded gold standards"}
{"id":"babygpt-2tf","title":"3.10 KNOWN: Audit 1.1.8 Applying Chain Rule placement","description":"KNOWN ISSUE: Appears after KenLM/Sparsity tangents, may break narrative flow","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T19:13:54.365264-05:00","updated_at":"2025-12-20T19:41:38.060262-05:00","closed_at":"2025-12-20T19:41:38.060262-05:00","close_reason":"Closed"}
{"id":"babygpt-30e","title":"1.14 Audit Ch2 ChapterMap missing sections","description":"AUDIT: List all 13 Ch2 sections, compare to 6 ChapterMap waypoints. IDENTIFY: critical sections missing (softmax 2.7? synthesis 2.9?). CREATE TICKET to add missing waypoints if navigation UX suffers.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:11:39.002014-05:00","updated_at":"2025-12-20T20:24:36.059618-05:00","closed_at":"2025-12-20T20:24:36.059618-05:00","close_reason":"FIXED: Added missing ChapterMap waypoints for sections 2.5, 2.7, 2.8, 2.9","comments":[{"id":10,"issue_id":"babygpt-30e","author":"andrewlouis","text":"NEEDS_FIX: ChapterMap has 6 waypoints but Chapter 2 has 14 sections (including subsections). Critical missing waypoints: 2.5 (Embedding Lookup - important mechanical detail), 2.7 (Softmax - critical for probabilities), 2.8 (Tensors - batching), 2.9 (Synthesis - ties counts to coordinates). Recommendation: Add waypoints for 2.5, 2.7, and 2.9 at minimum. 2.8 optional but helpful for navigation.","created_at":"2025-12-21T00:39:13Z"}]}
{"id":"babygpt-3ch","title":"Dot Product: Add 3B1B-quality geometric animations","description":"GeometricDotProductViz: SVG arrows with projection/shadow animation. Vectors as arrows from origin (cyan A, magenta B). Shadow animation sequence: perpendicular drop, landing point, multiply by |B|. Interactive drag to change angle. Insert BEFORE existing DotProductViz. Pattern: follow GradientDescentViz for SVG+CSS transitions.","status":"closed","issue_type":"feature","created_at":"2025-12-20T22:13:12.208942-05:00","updated_at":"2025-12-20T22:30:35.703355-05:00","closed_at":"2025-12-20T22:30:35.703355-05:00","close_reason":"Implemented GeometricDotProductViz with 3B1B-style visualization: draggable vector arrows, projection/shadow animation, angle arc (green for positive, red for negative), real-time dot product calculation, magnitude breakdown. Added bridge text connecting geometric 'shadow' view to probability 'overlap' view."}
{"id":"babygpt-3jd","title":"task","description":"Perplexity is first used at line 757 (section 1.1.7.1 'One Billion Word Benchmark' callout) without definition. The formula (perplexity = 2^H) appears later at line 903 in Exercise 1.1. REMEDIATION: Add perplexity definition (perplexity = 2^H where H is cross-entropy) either: (1) before line 757, OR (2) add forward reference callout at line 757 like 'perplexity (a metric we'll define shortly)' and ensure clear definition by line 903.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:56:01.399602-05:00","updated_at":"2025-12-20T20:27:41.047137-05:00","closed_at":"2025-12-20T20:27:41.047137-05:00","close_reason":"FIXED: Added inline definition of perplexity at first use (line 757): explains it measures model confusion as effective number of choices, lower is better, with example"}
{"id":"babygpt-3u3","title":"2.10 Gap: Why this gradient is the right direction","description":"Line ~1088-1090: Gradient formula given as 'predicted centroid minus actual embedding'. Shows WHAT, not WHY this is the right direction. FIX: Add intuition: gradient descent moves embeddings to reduce loss. The gradient points toward where the embedding SHOULD have been (the actual) and away from where it wrongly pointed (other candidates). It's literally 'move toward truth, away from mistakes'.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:50:32.099972-05:00","updated_at":"2025-12-20T21:52:27.317001-05:00","closed_at":"2025-12-20T21:52:27.317001-05:00","close_reason":"Fixed: Added WHY this direction - score = context·candidate, moving closer to E[actual] increases dot product with right answer → higher probability → lower loss"}
{"id":"babygpt-3w3","title":"Restore missing Chapter 1 callouts","description":"Add: This Becomes the Training Objective, Shannon's Information Theory, Meet the engineers, The Engineering Workhorse: KenLM","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T18:34:04.240474-05:00","updated_at":"2025-12-20T18:47:03.787481-05:00","closed_at":"2025-12-20T18:47:03.787481-05:00","close_reason":"Closed","comments":[{"id":1,"issue_id":"babygpt-3w3","author":"andrewlouis","text":"Added: This Becomes the Training Objective, Shannon's Information Theory (Citations), When Was This the Dominant Approach, From Surprise to Loss","created_at":"2025-12-20T23:38:34Z"},{"id":4,"issue_id":"babygpt-3w3","author":"andrewlouis","text":"Added: Sampling: Let It Talk (intro paragraphs before A concrete benchmark)","created_at":"2025-12-20T23:42:00Z"},{"id":5,"issue_id":"babygpt-3w3","author":"andrewlouis","text":"Remaining candidates from backup not in current: Build a toy model, Build the pipeline, Define the goal, Dot Product, Grassmann's Vision, Hit the limit, Meet the engineers, Overlap Isn't Meaning, Pick the biggest term, Retrain on corpus, Shannon's Question, Solution 1: Decomposition, Sort by score/coordinate, The Atoms, The Embedding Table, The Engineering Workhorse: KenLM, The Ground Truth, The Handoff, The Job Description, The Math: Chain Rule","created_at":"2025-12-20T23:43:44Z"},{"id":6,"issue_id":"babygpt-3w3","author":"andrewlouis","text":"Analysis complete: Most 'missing' titles are: (1) ChapterMap navigation entries (Build a toy model, Define the goal, Hit the limit, Meet the engineers, The Ground Truth, The Handoff - not actual content sections), (2) Interactive component button labels (Pick the biggest term, Sort characters by score, Retrain on corpus), (3) Content exists under different names (Overlap Isn't Meaning → Overlap vs. Understanding, Solution 1: Decomposition → content at line 337, Shannon's Question → content at line 105). All actual content sections have been restored.","created_at":"2025-12-20T23:45:49Z"}]}
{"id":"babygpt-431","title":"1.1.3 Gap: Why expect transfer between 'the cat' and 'the dog'","description":"Line ~400: P=0 for unseen context stated as problem, but WHY should we expect 'the cat' knowledge to help with 'the dog'? What principle? FIX: Add explicit statement: humans generalize because 'cat' and 'dog' share syntactic role (noun after article). Counting models have no notion of 'role' — only exact string match. This is the fundamental limit we're building toward.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:47:52.673357-05:00","updated_at":"2025-12-20T20:56:09.459048-05:00","closed_at":"2025-12-20T20:56:09.459048-05:00","close_reason":"FIXED: Added explicit explanation of syntactic role as basis for generalization - humans expect 'cat' and 'dog' to be related because they share grammatical function (nouns after article), while counting models lack this notion of role"}
{"id":"babygpt-43p","title":"9.3 Redundancy audit: why embeddings motivation","description":"AUDIT: Compare embedding motivation in 1.6, 1.7, 2.1, 2.2. IF excessive: create ticket to reduce OR add 'building on the motivation from...' to make spiral pedagogy explicit.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:17:08.898664-05:00","updated_at":"2025-12-20T20:29:54.992536-05:00","closed_at":"2025-12-20T20:29:54.992536-05:00","close_reason":"PASS: 1.6/1.7 set up the problem (sparsity), 2.1/2.2 provide the solution (embeddings). Progressive build-up, not redundancy."}
{"id":"babygpt-4bi","title":"3.8 KNOWN: Audit 1.1.7.1 KenLM placement","description":"KNOWN ISSUE: Engineering (hashing, linear probing) before motivation. Check if decoder/beam search concepts introduced without context","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T19:13:33.283801-05:00","updated_at":"2025-12-20T19:40:32.292831-05:00","closed_at":"2025-12-20T19:40:32.292831-05:00","close_reason":"Closed"}
{"id":"babygpt-4wn","title":"CSS: Extract card/panel background patterns to utilities","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T23:18:11.182352-05:00","updated_at":"2025-12-20T23:30:02.384798-05:00","closed_at":"2025-12-20T23:30:02.384798-05:00","close_reason":"Closed"}
{"id":"babygpt-5dh","title":"GradientDescentViz: Polish sweep","description":"Audit GradientDescentViz for:\n- Theme consistency (colors, fonts, spacing)\n- Visual polish (gradients, transitions, hover states)\n- Accessibility (aria labels, keyboard nav)\n- Mobile responsiveness\n- Document patterns to replicate in other vizzes","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T22:54:04.481612-05:00","updated_at":"2025-12-20T22:54:57.310352-05:00","closed_at":"2025-12-20T22:54:57.310352-05:00","close_reason":"Wrong - this IS a gold standard (Dec 15), not needing sweep"}
{"id":"babygpt-5k0","title":"4.11 Audit 2.10 gradient formula dependencies","description":"AUDIT: Read section 2.10 gradient formula, verify all prereqs present: dot product (2.6), softmax (2.7), cross-entropy. IF any missing: add SectionLink. Check if formula has intuitive explanation.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:14:23.421747-05:00","updated_at":"2025-12-20T19:56:29.380412-05:00","closed_at":"2025-12-20T19:56:29.380412-05:00","close_reason":"Closed"}
{"id":"babygpt-5ux","title":"1.3 Gap: Causal mask never explained","description":"Line ~1418-1422: 'Causal Mask' mentioned but never explained. What does 'blocking vision' mean mathematically? FIX: Add Callout explaining causal masking. In attention, each position can 'see' other positions. Causal mask sets attention weights to 0 for future positions (i \u003e j). Mathematically: mask[i,j] = 0 if j \u003e i, else 1. Multiply attention scores by mask before softmax.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:48:55.60735-05:00","updated_at":"2025-12-20T21:21:05.10468-05:00","closed_at":"2025-12-20T21:21:05.10468-05:00","close_reason":"FIXED: First principles - 'When predicting char 5, only look at 0-4. If you could see 5, you'd copy it.' No jargon (attention/autoregressive/time arrow)."}
{"id":"babygpt-665","title":"9.1 Redundancy audit: sparsity explanations","description":"AUDIT: Compare sparsity discussion in 1.1.2, 1.1.3, 1.1.7.2, 1.6. Document what each adds. IF excessive overlap: create ticket to consolidate OR add 'As we saw in section X...' callbacks to make repetition intentional.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:17:08.324132-05:00","updated_at":"2025-12-20T19:51:53.838302-05:00","closed_at":"2025-12-20T19:51:53.838302-05:00","close_reason":"Closed"}
{"id":"babygpt-66l","title":"Inline code styling polish sweep - fix background and visual consistency across all chapters","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T23:10:53.971804-05:00","updated_at":"2025-12-20T23:14:34.396536-05:00","closed_at":"2025-12-20T23:14:34.396536-05:00","close_reason":"Closed"}
{"id":"babygpt-6ar","title":"10.1 Transition audit: 1.1.6-\u003e1.1.7.1","description":"AUDIT: Check bridge from 'building probabilities from corpus' to 'KenLM engineering'. IF abrupt: create ticket to add transition paragraph like 'Now that we can build probabilities, how do we make this fast?'","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:17:27.1061-05:00","updated_at":"2025-12-20T19:53:45.333726-05:00","closed_at":"2025-12-20T19:53:45.333726-05:00","close_reason":"Closed"}
{"id":"babygpt-6bq","title":"GradientTraceDemo: Polish sweep","description":"Sweep GradientTraceDemo for:\n- Theme consistency (colors, fonts, spacing match existing vizzes)\n- Visual polish (code highlighting, step transitions, output formatting)\n- Accessibility (aria labels, keyboard nav for step buttons)\n- Mobile responsiveness (two-panel layout on small screens)\n- Compare against CodeWalkthrough/NeuralTrainingDemo as gold standard","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T22:51:32.019662-05:00","updated_at":"2025-12-20T22:52:16.390006-05:00","closed_at":"2025-12-20T22:52:16.390006-05:00","close_reason":"Recreating with expanded gold standards"}
{"id":"babygpt-6fl","title":"3.15 Audit 1.7 What's Next dependencies","description":"AUDIT: Read section 1.7, verify embeddings are foreshadowed but NOT explained. IF too much detail: create ticket to trim. IF not enough foreshadowing: add 'we need a way to share knowledge' hook.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:13:55.799332-05:00","updated_at":"2025-12-20T19:42:29.661732-05:00","closed_at":"2025-12-20T19:42:29.661732-05:00","close_reason":"Closed"}
{"id":"babygpt-6r7","title":"PHASE 6: Terminology Consistency","description":"Audit term usage consistency across chapters (7 issues)","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-20T19:10:59.510839-05:00","updated_at":"2025-12-20T20:30:34.498443-05:00","closed_at":"2025-12-20T20:30:34.498443-05:00","close_reason":"Terminology consistency audit complete. All 7 issues passed: context/history, token/character, embedding/vector, loss/surprise/cross-entropy, logits/scores, context_length/block_size/T, notation consistent."}
{"id":"babygpt-6sy","title":"2.4 Validate Ch1 invariant: Training pairs from sliding window","description":"AUDIT: Read sections 1.3.x, verify (context, target) pair generation is clearly shown. IF missing: create ticket to add SlidingWindowDemo or visual. IF present but unclear: create ticket to add step-by-step walkthrough.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:12:00.861869-05:00","updated_at":"2025-12-20T19:32:32.920995-05:00","closed_at":"2025-12-20T19:32:32.920995-05:00","close_reason":"Closed"}
{"id":"babygpt-6u9","title":"3.4 Audit 1.1.3 Why This Happens dependencies","description":"AUDIT: Read section 1.1.3, verify 27^N explosion formula comes AFTER joint probability is motivated. Check ExplosionDemo has adequate textual setup. IF gap: add setup paragraph.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:13:32.143694-05:00","updated_at":"2025-12-20T19:42:01.188407-05:00","closed_at":"2025-12-20T19:42:01.188407-05:00","close_reason":"Closed"}
{"id":"babygpt-71u","title":"2.5 Validate Ch1 invariant: X[i] shifted by 1 = Y[i]","description":"AUDIT: Read sections 1.3.2/1.4, verify 'targets are inputs shifted by 1' is explicitly shown. IF missing: create ticket to add visual or code showing X/Y alignment. IF unclear: add explicit explanation.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:12:01.151008-05:00","updated_at":"2025-12-20T19:32:33.208679-05:00","closed_at":"2025-12-20T19:32:33.208679-05:00","close_reason":"Closed"}
{"id":"babygpt-7eh","title":"2.6 Gap: Why similarity must distribute over addition","description":"Line ~704-710: The constraint (αa + βb)·c = α(a·c) + β(b·c) is given but not motivated. WHY require this? What breaks without it? FIX: Add explanation: if we blend embeddings (weighted average), we want the similarity of the blend to be the weighted average of similarities. This is ESSENTIAL for attention, where we compute weighted sums of values. Linearity = predictable blending behavior.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:50:17.439573-05:00","updated_at":"2025-12-20T21:46:40.899782-05:00","closed_at":"2025-12-20T21:46:40.899782-05:00","close_reason":"Fixed: Concrete numbers - 'a' scores 0.7, 'e' scores 0.5, average scores 0.6. You already know the answer."}
{"id":"babygpt-7g8","title":"7.5 Difficulty audit: Ch2 internal flow","description":"AUDIT: Map difficulty curve through Ch2 (philosophical-\u003econceptual-\u003emechanical-\u003emath). IF abrupt jumps: identify specific section boundaries needing transition text.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:16:29.491128-05:00","updated_at":"2025-12-20T20:07:49.488919-05:00","closed_at":"2025-12-20T20:07:49.488919-05:00","close_reason":"Closed"}
{"id":"babygpt-7zm","title":"SoftmaxSimplexViz: Polish sweep","description":"Sweep SoftmaxSimplexViz for:\n- Theme consistency (colors, fonts, spacing match existing vizzes)\n- Visual polish (gradients, transitions, hover states, ambient glow?)\n- Accessibility (aria labels, keyboard nav)\n- Mobile responsiveness\n- Trail animation smoothness\n\nGold standards to reference:\n- GradientDescentViz (ambient glow, formula display, step interaction)\n- CrossEntropyViz (curve rendering, slider interaction, dynamic labels)\n- CodeWalkthrough (panel layouts)\n- NeuralTrainingDemo (interactive training viz)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T22:52:30.870818-05:00","updated_at":"2025-12-20T23:11:20.692197-05:00","closed_at":"2025-12-20T23:11:20.692197-05:00","close_reason":"Closed"}
{"id":"babygpt-80n","title":"4.4 Audit 2.4 Vectors Are Storage dependencies","description":"AUDIT: Read section 2.4, verify transition from 'what to store' (2.3) to 'how to store it'. Check one-hot encoding connects to later matrix mult. IF gap: add bridging sentence.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:14:21.389554-05:00","updated_at":"2025-12-20T19:52:11.048675-05:00","closed_at":"2025-12-20T19:52:11.048675-05:00","close_reason":"Closed"}
{"id":"babygpt-882","title":"6.1 Terminology audit: context vs history","description":"AUDIT: grep both terms in Ch1/Ch2, document usage counts and locations. IF inconsistent: create ticket to standardize on one term with search-replace. IF interchangeable: add callout explaining both terms.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:16:10.802391-05:00","updated_at":"2025-12-20T20:29:36.974728-05:00","closed_at":"2025-12-20T20:29:36.974728-05:00","close_reason":"PASS: 'context' is used consistently (60 uses in Ch1, 39 in Ch2). 'history' is rarely used. Terminology is clear."}
{"id":"babygpt-8il","title":"CSS: Standardize transition timing to design tokens","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T23:18:12.085686-05:00","updated_at":"2025-12-20T23:30:48.107098-05:00","closed_at":"2025-12-20T23:30:48.107098-05:00","close_reason":"Closed"}
{"id":"babygpt-8jy","title":"PHASE 5: Cross-Reference Validation","description":"Validate all SectionLinks point correctly (5 issues)","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-20T19:10:59.192094-05:00","updated_at":"2025-12-20T20:30:33.445132-05:00","closed_at":"2025-12-20T20:30:33.445132-05:00","close_reason":"Cross-reference validation complete. Fixed: 2 incorrect SectionLinks in Ch2 exercises (2.2→2.3)."}
{"id":"babygpt-8lk","title":"4.7 Audit 2.7 Softmax dependencies","description":"AUDIT: Read section 2.7, verify it connects to Ch1 'sum to 1' invariant. Check logits are introduced before softmax applied. IF no Ch1 connection: add 'Recall from Ch1 that...' callout.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:14:22.260705-05:00","updated_at":"2025-12-20T19:54:25.361206-05:00","closed_at":"2025-12-20T19:54:25.361206-05:00","close_reason":"Closed"}
{"id":"babygpt-8ne","title":"10.3 Transition audit: 1.5-\u003e1.6","description":"AUDIT: Check bridge from 'what we built' summary to 'the limit'. IF abrupt: create ticket to add transition like 'Everything works... until it doesn't.'","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:17:27.686574-05:00","updated_at":"2025-12-20T19:53:45.925594-05:00","closed_at":"2025-12-20T19:53:45.925594-05:00","close_reason":"Closed"}
{"id":"babygpt-8sj","title":"8.3 Gap audit: gradient","description":"AUDIT: Find first 'gradient' usage, verify 'slope' intuition is adequate prep. IF gap: create ticket to add intuitive gradient intro in 2.10 before formula.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:16:46.520425-05:00","updated_at":"2025-12-20T20:10:58.420491-05:00","closed_at":"2025-12-20T20:10:58.420491-05:00","close_reason":"Closed"}
{"id":"babygpt-8us","title":"1.12 Validate Ch2 map waypoint 2.6 Dot Product","description":"AUDIT: Navigate to 2.6, verify 'similarity score you can compute' description. IF mismatch: update. Check if dot product as similarity is clearly established.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:11:38.416958-05:00","updated_at":"2025-12-20T19:36:27.88625-05:00","closed_at":"2025-12-20T19:36:27.88625-05:00","close_reason":"Closed"}
{"id":"babygpt-8yn","title":"3.12 Audit 1.3 Sliding Window dependencies","description":"AUDIT: Read section 1.3, verify it requires tokenization (1.2) and refs decomposition from 1.1.5. IF missing refs: add SectionLinks. Check if sliding window concept has visual support.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:13:54.936707-05:00","updated_at":"2025-12-20T19:42:28.81226-05:00","closed_at":"2025-12-20T19:42:28.81226-05:00","close_reason":"Closed"}
{"id":"babygpt-9j5","title":"2.8 Validate Ch2 invariant: Embeddings give learnable geometry","description":"AUDIT: Read sections 2.1/2.4, verify 'embeddings provide learnable geometry' is established. IF missing: create ticket to add visual showing geometry emerging from training. IF unclear: add Grassmann connection.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:12:19.348171-05:00","updated_at":"2025-12-20T19:42:48.676355-05:00","closed_at":"2025-12-20T19:42:48.676355-05:00","close_reason":"Closed"}
{"id":"babygpt-9qo","title":"2.3 Validate Ch1 invariant: Tokenization via stoi/itos","description":"AUDIT: Read sections 1.2.x, verify stoi/itos pattern is established with code examples. IF missing code: create ticket to add TokenizerDemo or code block. IF pattern unclear: create ticket to add explicit naming.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:12:00.570455-05:00","updated_at":"2025-12-20T19:32:32.628999-05:00","closed_at":"2025-12-20T19:32:32.628999-05:00","close_reason":"Closed"}
{"id":"babygpt-9vf","title":"2.10 Validate Ch2 invariant: Embedding lookup is E[ix]","description":"AUDIT: Read sections 2.5.x, verify embedding lookup as row selection E[ix] is shown with code. IF missing code: create ticket to add NumPy example. IF unclear: add visual showing row extraction.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:12:19.932113-05:00","updated_at":"2025-12-20T19:44:30.92558-05:00","closed_at":"2025-12-20T19:44:30.92558-05:00","close_reason":"Closed"}
{"id":"babygpt-a2s","title":"6.7 KNOWN: Audit notation shift Ch1-\u003eCh2","description":"KNOWN ISSUE: Document ALL notation changes (probability notation, variable names, tensor shapes). Create ticket to add 'Notation Bridge' section at Ch2 start if significant differences found.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T19:16:12.505195-05:00","updated_at":"2025-12-20T20:30:03.290638-05:00","closed_at":"2025-12-20T20:30:03.290638-05:00","close_reason":"PASS: Notation is consistent across chapters. Variables introduced with same meaning: P(next|c), E[ix], D, T, B. Ch2 builds on Ch1 notation without conflict."}
{"id":"babygpt-a61","title":"4.1 Audit 2.1 Grassmann dependencies","description":"AUDIT: Read section 2.1, verify it refs Ch1 lookup table limitation. Check 'memorization vs generalization' connects to Ch1 sparsity. IF no Ch1 ref: add SectionLink to 1.6.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:14:20.532018-05:00","updated_at":"2025-12-20T19:49:30.927063-05:00","closed_at":"2025-12-20T19:49:30.927063-05:00","close_reason":"Closed"}
{"id":"babygpt-a7p","title":"10.6 Transition audit: 2.9-\u003e2.10","description":"AUDIT: Check bridge from 'synthesis: we have a map' to 'the nudge: let's make it move'. IF abrupt: create ticket to add motivating question like 'But how do we make the map accurate?'","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:17:28.568598-05:00","updated_at":"2025-12-20T20:19:47.08151-05:00","closed_at":"2025-12-20T20:19:47.08151-05:00","close_reason":"Closed"}
{"id":"babygpt-ae7","title":"2.12 Validate Ch2 invariant: Dot product is similarity metric","description":"AUDIT: Read section 2.6, verify dot product established as primary similarity metric with formula and example. IF missing formula: add. IF missing example: add WorkedExample.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:12:20.503823-05:00","updated_at":"2025-12-20T19:46:16.79037-05:00","closed_at":"2025-12-20T19:46:16.79037-05:00","close_reason":"Closed"}
{"id":"babygpt-ahx","title":"9.4 Redundancy audit: sum-to-1 rule","description":"AUDIT: Compare 'probabilities sum to 1' in 1.1.1 vs 2.7. IF Ch2 ref is unnecessary: create ticket to add proper callback 'Recall from Ch1 that...' instead of re-explaining.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:17:09.182071-05:00","updated_at":"2025-12-20T20:29:55.921523-05:00","closed_at":"2025-12-20T20:29:55.921523-05:00","close_reason":"PASS: Ch1 establishes sum-to-1 as probability axiom (1.1.1), Ch2 references it as motivation for softmax (2.7 line 804). Callback reinforces learning."}
{"id":"babygpt-ar2","title":"1.2 Gap: Why counting models can't share information","description":"Line ~574-575: 'Counting model can't share information across contexts unless literal overlap' — but WHY? What prevents generalization at data structure level? FIX: Add explanation: a hash table maps exact keys to values. There's no notion of 'similar keys'. Hash('cat sat') and Hash('dog sat') are unrelated integers. The data structure has no geometry — keys are just addresses, not locations in a space.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:48:32.990534-05:00","updated_at":"2025-12-20T21:09:03.018087-05:00","closed_at":"2025-12-20T21:09:03.018087-05:00","close_reason":"FIXED: Added data structure explanation - hash tables map exact keys to unrelated integers with no geometry for similarity"}
{"id":"babygpt-ars","title":"CrossEntropyViz: Polish sweep","description":"Audit CrossEntropyViz for:\n- Theme consistency (colors, fonts, spacing)\n- Visual polish (curve rendering, guide lines, axis labels)\n- Accessibility (aria labels, keyboard nav)\n- Mobile responsiveness\n- Document patterns to replicate in other vizzes","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T22:54:05.323407-05:00","updated_at":"2025-12-20T22:54:57.553713-05:00","closed_at":"2025-12-20T22:54:57.553713-05:00","close_reason":"Wrong - this IS a gold standard (Dec 19), not needing sweep"}
{"id":"babygpt-bgc","title":"8.6 Gap audit: one-hot encoding","description":"AUDIT: Verify one-hot defined before matrix multiplication explanation in 2.5. IF gap: create ticket to add one-hot intro earlier.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:16:47.356896-05:00","updated_at":"2025-12-20T20:13:53.369802-05:00","closed_at":"2025-12-20T20:13:53.369802-05:00","close_reason":"Closed"}
{"id":"babygpt-bpm","title":"1.1.7.1 Gap: Why pointer overhead is bad (cache misses)","description":"Line ~1030-1038: Memory calculation concrete but doesn't explain WHY pointer overhead hurts. FIX: Add 1-2 sentences on CPU cache hierarchy. Following a pointer = random memory access = cache miss = ~100 cycles. Array traversal = sequential access = cache hit = ~1 cycle. Pointer-chasing is 100x slower per access. At millions of lookups/second, this dominates runtime.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:48:40.398536-05:00","updated_at":"2025-12-20T21:10:02.264407-05:00","closed_at":"2025-12-20T21:10:02.264407-05:00","close_reason":"FIXED: Added hardware mechanism explanation for pointer overhead in KenLM section. Cache miss (~100 cycles) vs L1 cache hit (~1 cycle) makes 100× difference at millions of lookups/second."}
{"id":"babygpt-bs5","title":"6.2 Terminology audit: token vs character","description":"AUDIT: find all 'token'/'character' occurrences. IF confusing transitions: add clarifying phrases like 'in our character-level model, each token is a single character'. Document where explicit clarification needed.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:16:11.081601-05:00","updated_at":"2025-12-20T20:29:37.892023-05:00","closed_at":"2025-12-20T20:29:37.892023-05:00","close_reason":"PASS: 'character' used for tutorial's char-level focus (91 uses). 'token' used when discussing general concepts (44 uses). Clear distinction maintained."}
{"id":"babygpt-bzz","title":"1.2 Validate Ch1 map waypoint 1.1.5 Chain Rule","description":"AUDIT: Navigate to 1.1.5, verify description 'Turn P(text) into a product of P(next|context)' matches section. IF mismatch: update description to reflect actual section focus. Document what section actually covers.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:11:23.150647-05:00","updated_at":"2025-12-20T19:31:18.711913-05:00","closed_at":"2025-12-20T19:31:18.711913-05:00","close_reason":"Closed"}
{"id":"babygpt-c0k","title":"2.9 Validate Ch2 invariant: Similar = similar predictive role","description":"AUDIT: Read section 2.3, verify 'similar = similar next-char distributions' is explicit. IF missing: create ticket to add CharacterClusterViz or fingerprint comparison. IF implicit: add explicit definition.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:12:19.635791-05:00","updated_at":"2025-12-20T19:43:30.661081-05:00","closed_at":"2025-12-20T19:43:30.661081-05:00","close_reason":"Closed"}
{"id":"babygpt-c6g","title":"9.2 Redundancy audit: chain rule explanations","description":"AUDIT: Compare 1.1.5 and 1.1.8 chain rule content. IF 1.1.8 doesn't add value: create ticket to merge into 1.1.5 OR convert 1.1.8 to pure application/example.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:17:08.60991-05:00","updated_at":"2025-12-20T19:50:14.742334-05:00","closed_at":"2025-12-20T19:50:14.742334-05:00","close_reason":"Closed"}
{"id":"babygpt-c8j","title":"1.3 Validate Ch1 map waypoint 1.1.7.2 Sparsity Trap","description":"AUDIT: Navigate to 1.1.7.2, verify 'counting hits zeros' description. IF mismatch: update to match actual section content. Note if section covers more than just zero-probability problem.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:11:23.455896-05:00","updated_at":"2025-12-20T19:31:18.997429-05:00","closed_at":"2025-12-20T19:31:18.997429-05:00","close_reason":"Closed"}
{"id":"babygpt-cax","title":"2.2 Validate Ch1 invariant: Probabilities sum to 1","description":"AUDIT: Read section 1.1.1, verify 'probabilities sum to 1' is explicitly stated and demonstrated. IF missing: create ticket to add axiom statement. IF implicit only: create ticket to make explicit.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:12:00.276732-05:00","updated_at":"2025-12-20T19:32:32.328595-05:00","closed_at":"2025-12-20T19:32:32.328595-05:00","close_reason":"Closed"}
{"id":"babygpt-cbs","title":"2.11 Validate Ch2 invariant: Shape [B,T] -\u003e [B,T,D]","description":"AUDIT: Read section 2.8, verify shape transformation [B,T]-\u003e[B,T,D] is explicitly shown. IF missing: create ticket to add TensorShapeBuilder visual. IF present but unclear: add step-by-step shape trace.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:12:20.216665-05:00","updated_at":"2025-12-20T19:45:33.564581-05:00","closed_at":"2025-12-20T19:45:33.564581-05:00","close_reason":"Closed"}
{"id":"babygpt-cxl","title":"2.1 Gap: Abrupt jump from colors to language","description":"Line ~113-119: MASSIVE jump from 'abstract relationships can be coordinates' to language. What makes language LIKE colors? Answer comes 120 lines later. FIX: Add bridge sentence immediately: 'Colors have measurable relationships (wavelength ratios). Language has measurable relationships too (co-occurrence statistics). If we can measure it, we can coordinatize it. That's the move.'","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:49:04.826141-05:00","updated_at":"2025-12-20T21:26:25.553877-05:00","closed_at":"2025-12-20T21:26:25.553877-05:00","close_reason":"FIXED: Replaced vague 'measurable relationships' with specific procedures — Grassmann's knob-matching experiment, our counting. Both produce numbers; previous paragraph establishes numbers=coordinates."}
{"id":"babygpt-def","title":"Extract Slider reusable component (styled range input with label, used in 19 files)","description":"Create a reusable Slider component (styled \u003cinput type=range\u003e) with label, optional value display, min/max/step, and onChange; centralize the CSS used across ~19 files. Export from src/components/index.ts and migrate call sites.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T23:38:22.889167-05:00","updated_at":"2025-12-21T00:24:44.480982-05:00","closed_at":"2025-12-21T00:24:44.480982-05:00","close_reason":"Added Slider component and migrated all range inputs to it"}
{"id":"babygpt-dfs","title":"CSS: Extract ambientGlow pattern to shared utility (13 files)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T23:18:10.282355-05:00","updated_at":"2025-12-20T23:28:50.945953-05:00","closed_at":"2025-12-20T23:28:50.945953-05:00","close_reason":"Closed"}
{"id":"babygpt-dut","title":"1.7 Audit Ch1 ChapterMap missing sections","description":"AUDIT: List all 18 Ch1 sections, compare to 6 ChapterMap waypoints. IDENTIFY: critical sections missing from map (tokenization 1.2? context length 1.3.1?). CREATE TICKET to add missing waypoints if navigation UX suffers.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:11:24.620052-05:00","updated_at":"2025-12-20T19:31:20.132315-05:00","closed_at":"2025-12-20T19:31:20.132315-05:00","close_reason":"Closed"}
{"id":"babygpt-dx8","title":"PHASE 9: Redundancy Detection","description":"Find excessive repetition vs useful reinforcement (4 issues)","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-20T19:11:00.385827-05:00","updated_at":"2025-12-20T20:30:44.386463-05:00","closed_at":"2025-12-20T20:30:44.386463-05:00","close_reason":"Redundancy detection audit complete. All 4 issues passed: sparsity builds progressively, chain rule sections complement, embeddings motivation scaffolds, sum-to-1 callback reinforces learning."}
{"id":"babygpt-dzx","title":"2.7 Gap: Why exponentiation amplification is useful","description":"Line ~818-819: 'Exponentiation amplifies differences' — but WHY is this useful? What would happen with a different function? FIX: Add explanation: we want the model to be CONFIDENT — put most probability on one answer. Linear scaling preserves relative gaps. Exponential WIDENS gaps, making the winner dominate. This is 'soft argmax' — we approximate max() but keep it differentiable.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:50:24.587271-05:00","updated_at":"2025-12-20T21:48:11.854582-05:00","closed_at":"2025-12-20T21:48:11.854582-05:00","close_reason":"Fixed: Concrete numbers [2.0,1.5]→[7.4,4.5]→[0.62,0.38]. WHY: hedging wastes probability, amplification rewards commitment."}
{"id":"babygpt-e0e","title":"Restore missing Chapter 2 sections","description":"Add: Grassmann's Vision Finally Built, Sort characters by score, Sort characters by this coordinate, Solution 1: Decomposition, Overlap Isn't Meaning","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T18:34:15.036781-05:00","updated_at":"2025-12-20T18:48:42.893995-05:00","closed_at":"2025-12-20T18:48:42.893995-05:00","close_reason":"Closed","comments":[{"id":7,"issue_id":"babygpt-e0e","author":"andrewlouis","text":"Verified: Grassmann's Vision content exists at lines 1647-1665 (within Section 2.10 The Nudge). Sort characters buttons are component labels, not sections. Overlap section exists as 2.6. All content present.","created_at":"2025-12-20T23:48:39Z"}]}
{"id":"babygpt-eeb","title":"3.6 Audit 1.1.5 Chain Rule dependencies","description":"AUDIT: Read section 1.1.5, verify all prereqs present: joint prob from 1.1.2, conditional prob from 1.1.4. IF any missing: add SectionLink backward reference.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:13:32.718033-05:00","updated_at":"2025-12-20T19:42:01.781533-05:00","closed_at":"2025-12-20T19:42:01.781533-05:00","close_reason":"Closed"}
{"id":"babygpt-egk","title":"4.3 Audit 2.3 What Can We Measure dependencies","description":"AUDIT: Read section 2.3, verify fingerprint/similarity concept is established BEFORE dot product in 2.6. Check P(next|c) connects to Ch1. IF no Ch1 connection: add SectionLink.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:14:21.099299-05:00","updated_at":"2025-12-20T20:25:32.224877-05:00","closed_at":"2025-12-20T20:25:32.224877-05:00","close_reason":"FIXED: Added SectionLink to Chapter 1.1.5 (Chain Rule) in Section 2.3 when introducing P(next|c)","comments":[{"id":12,"issue_id":"babygpt-egk","author":"andrewlouis","text":"NEEDS_FIX: Section 2.3 establishes P(next|c) fingerprint concept but lacks explicit reference to Chapter 1 counting/probability foundations. Recommendation: Add SectionLink to Chapter 1 when introducing P(next|c) to show where this counting concept comes from.","created_at":"2025-12-21T00:51:28Z"}]}
{"id":"babygpt-esr","title":"3.1 Audit 1.1 Physics dependencies","description":"AUDIT: Read section 1.1, check for forward references to later concepts. Verify Shannon 1.3 bits/char target is introduced. IF forward refs found: create ticket to remove or add 'we'll see later' framing. IF Shannon missing: add.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:13:31.302577-05:00","updated_at":"2025-12-20T19:42:00.260142-05:00","closed_at":"2025-12-20T19:42:00.260142-05:00","close_reason":"Closed"}
{"id":"babygpt-f94","title":"3.3 Audit 1.1.2 Problem With Sequences dependencies","description":"AUDIT: Read section 1.1.2, verify joint probability P(x1,x2,...) is introduced AFTER single-token probability in 1.1.1. IF out of order: create ticket to add bridging sentence or reorder.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:13:31.86495-05:00","updated_at":"2025-12-20T19:42:00.870741-05:00","closed_at":"2025-12-20T19:42:00.870741-05:00","close_reason":"Closed"}
{"id":"babygpt-fa1","title":"5.1 Validate SectionLink in 1.2 to 1.1","description":"AUDIT: Line 1058 in Ch1, find SectionLink to 1.1. Verify 'sparsity problem' text accurately reflects 1.1 content. IF inaccurate: update link text to match what 1.1 actually covers.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:14:39.346986-05:00","updated_at":"2025-12-20T19:43:40.154249-05:00","closed_at":"2025-12-20T19:43:40.154249-05:00","close_reason":"Closed"}
{"id":"babygpt-fgj","title":"2.5 Gap: Why one-hot leads to gradients","description":"Line ~610-611: 'One-hot decides which row gets credit' — but WHY does this lead to gradients? Gradient flow unexplained. FIX: Add explanation of gradient routing. One-hot selects row i. Loss depends on row i. Gradient ∂L/∂E[i] is non-zero ONLY for row i. One-hot acts as a 'router' — it tells backprop which embedding to update. All other rows have zero gradient for this example.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:50:09.295596-05:00","updated_at":"2025-12-20T21:42:32.33788-05:00","closed_at":"2025-12-20T21:42:32.33788-05:00","close_reason":"Fixed: Explained gradient routing from first principles - if row 3 is used and prediction is wrong, only row 3 can be adjusted. No backprop jargon."}
{"id":"babygpt-fp5","title":"1.9 Validate Ch2 map waypoint 2.2 Reuse Question","description":"AUDIT: Navigate to 2.2, verify 'context explosion' description. IF mismatch: update. Check if section clearly establishes the combinatorial explosion problem.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:11:37.51601-05:00","updated_at":"2025-12-20T19:31:56.502713-05:00","closed_at":"2025-12-20T19:31:56.502713-05:00","close_reason":"Closed"}
{"id":"babygpt-g31","title":"Extract DataRow reusable component (key-value display pattern)","description":"Extract the repeated key/value row pattern (label + value + optional monospace styling) into a DataRow component and migrate call sites.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-20T23:38:23.72084-05:00","updated_at":"2025-12-20T23:40:35.808249-05:00"}
{"id":"babygpt-ghl","title":"1.1.1 Gap: Why rare events NEED high surprise","description":"Line ~214-219: Log formula shown but the NECESSITY isn't derived. What breaks with a different function? FIX: Add a Callout showing that log is the UNIQUE function satisfying: (1) additive for independent events, (2) monotonic in probability, (3) continuous. Cite Shannon's uniqueness theorem or derive from first principles.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:47:35.057347-05:00","updated_at":"2025-12-20T20:53:26.119947-05:00","closed_at":"2025-12-20T20:53:26.119947-05:00","close_reason":"FIXED: Added explanation of Shannon's uniqueness theorem showing log is the unique function satisfying additivity, monotonicity, and continuity requirements for surprise"}
{"id":"babygpt-gmw","title":"2.10 Gap: Why similar stats → nearby points (not proven)","description":"Line ~1129-1134: 'Similar statistics → similar gradients → nearby points' is CLAIMED but not PROVEN. It's a restatement, not a derivation. FIX: Add rigorous explanation. If tokens a,b have similar P(next|a) ≈ P(next|b), they make similar errors on similar examples. Similar errors = similar gradients. Gradient descent moves them in similar directions. Over many steps, they converge to nearby locations. Show this with the training viz.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:50:40.48566-05:00","updated_at":"2025-12-20T21:53:06.0745-05:00","closed_at":"2025-12-20T21:53:06.0745-05:00","close_reason":"Fixed: Concrete derivation - 'a' and 'e' both precede 'n', both get nudged toward E['n']. Same targets → same directions → nearby endpoints."}
{"id":"babygpt-hn3","title":"GeometricDotProductViz: Polish sweep","description":"Sweep GeometricDotProductViz for:\n- Theme consistency (colors, fonts, spacing match existing vizzes)\n- Visual polish (gradients, transitions, hover states)\n- Accessibility (aria labels, keyboard nav)\n- Mobile responsiveness\n- Compare against GradientDescentViz as gold standard","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T22:51:30.304017-05:00","updated_at":"2025-12-20T22:52:15.874626-05:00","closed_at":"2025-12-20T22:52:15.874626-05:00","close_reason":"Recreating with expanded gold standards"}
{"id":"babygpt-hp1","title":"1.13 Validate Ch2 map waypoint 2.10 The Handoff","description":"AUDIT: Navigate to 2.10, check if ChapterMap says 'The Handoff' but section is titled 'The Nudge'. IF title mismatch: decide which name is better and update for consistency. Verify 'updating when wrong' description.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:11:38.709081-05:00","updated_at":"2025-12-20T20:23:37.219635-05:00","closed_at":"2025-12-20T20:23:37.219635-05:00","close_reason":"FIXED: ChapterMap title changed from 'The Handoff' to 'The Nudge' to match Section 2.10 title","comments":[{"id":9,"issue_id":"babygpt-hp1","author":"andrewlouis","text":"NEEDS_FIX: Title mismatch - ChapterMap says 'The Handoff' but Section 2.10 is titled 'The Nudge'. Need to choose one title and update both places for consistency. Recommendation: check which title better captures the content (gradient updates vs. handoff to next layer).","created_at":"2025-12-21T00:37:56Z"}]}
{"id":"babygpt-hsy","title":"4.9 Audit 2.9 Synthesis dependencies","description":"AUDIT: Read section 2.9, verify it properly synthesizes 2.1-2.8. Check 'arc' summary is accurate to actual content. IF inaccurate: update synthesis to match reality.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:14:22.838707-05:00","updated_at":"2025-12-20T19:55:46.76411-05:00","closed_at":"2025-12-20T19:55:46.76411-05:00","close_reason":"Closed"}
{"id":"babygpt-hxa","title":"1.1.2 Gap: Why probabilities must sum to 1","description":"Line ~351-357: 'Probabilities must sum to 1' stated as requirement but WHY? Is it definition, constraint, or convention? FIX: Add explanation that sum-to-1 is the DEFINITION of exhaustive mutually exclusive outcomes. If you're certain SOMETHING happens, the total certainty must be 100%. This enables the 'probability mass' metaphor.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:47:44.802076-05:00","updated_at":"2025-12-20T20:54:58.273538-05:00","closed_at":"2025-12-20T20:54:58.273538-05:00","close_reason":"FIXED: Added explanation that sum-to-1 is the definition of exhaustive mutually exclusive outcomes, not just a constraint. Introduced 'probability mass' metaphor and conservation of certainty concept."}
{"id":"babygpt-i3d","title":"3.5 Audit 1.1.4 Conditional Probability dependencies","description":"AUDIT: Read section 1.1.4, verify P(X|Y) 'given' notation is introduced BEFORE chain rule in 1.1.5 uses it. IF missing: create ticket to add conditional probability primer.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:13:32.427399-05:00","updated_at":"2025-12-20T19:42:01.496245-05:00","closed_at":"2025-12-20T19:42:01.496245-05:00","close_reason":"Closed"}
{"id":"babygpt-i3g","title":"7.4 Difficulty audit: Ch1 internal flow","description":"AUDIT: Map difficulty curve through Ch1 (theory-\u003eimpl-\u003etheory). IF abrupt jumps: create tickets to add transition paragraphs at specific locations. Document the curve.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:16:29.199543-05:00","updated_at":"2025-12-20T19:44:56.133937-05:00","closed_at":"2025-12-20T19:44:56.133937-05:00","close_reason":"Closed"}
{"id":"babygpt-i7a","title":"CSS: Refactor large files (DotProductViz 997 LOC, CharacterClusterViz 952 LOC)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T23:18:13.535944-05:00","updated_at":"2025-12-20T23:31:12.937696-05:00","closed_at":"2025-12-20T23:31:12.937696-05:00","close_reason":"Skip - files are well-structured, refactoring is high-risk low-reward"}
{"id":"babygpt-igj","title":"2.6 Validate Ch2 invariant: Replace tables with shared matrices","description":"AUDIT: Read section 2.2, verify 'replace context tables with shared matrices' claim. IF missing: create ticket to add explicit comparison diagram. IF present but unclear: add transition paragraph.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:12:18.757813-05:00","updated_at":"2025-12-20T19:41:00.558501-05:00","closed_at":"2025-12-20T19:41:00.558501-05:00","close_reason":"Closed"}
{"id":"babygpt-imn","title":"6.5 Terminology audit: logits vs scores","description":"AUDIT: grep 'logit'/'score' in Ch2. IF used interchangeably without explanation: add parenthetical '(also called scores)' at first logits usage. Document findings.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:16:11.928108-05:00","updated_at":"2025-12-20T20:29:53.058318-05:00","closed_at":"2025-12-20T20:29:53.058318-05:00","close_reason":"PASS: 'logits' consistently used for raw outputs before softmax (line 821: 'dot product gives us logits'). 'scores' used as general term for similarity scores. Relationship clear."}
{"id":"babygpt-imo","title":"CodeWalkthrough: Polish sweep","description":"Audit CodeWalkthrough for:\n- Theme consistency (colors, fonts, spacing)\n- Visual polish (code highlighting, step transitions)\n- Accessibility (aria labels, keyboard nav)\n- Mobile responsiveness\n- Document patterns to replicate in other vizzes","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T22:54:06.164784-05:00","updated_at":"2025-12-20T22:54:57.804254-05:00","closed_at":"2025-12-20T22:54:57.804254-05:00","close_reason":"Wrong - this IS a gold standard (Dec 19), not needing sweep"}
{"id":"babygpt-j2e","title":"5.2 Validate SectionLink in 1.3 to 1.1","description":"AUDIT: Line 1164 in Ch1, find SectionLink to 1.1. Verify 'Decomposition Strategy' matches what 1.1 calls it. IF different name: update to match actual terminology used in 1.1.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:14:39.640729-05:00","updated_at":"2025-12-20T19:43:40.445855-05:00","closed_at":"2025-12-20T19:43:40.445855-05:00","close_reason":"Closed"}
{"id":"babygpt-j3v","title":"10.5 Transition audit: 2.4-\u003e2.5","description":"AUDIT: Check bridge from 'vectors are storage' concept to 'how lookup works' mechanics. IF abrupt: create ticket to add 'Now let's see how to actually retrieve these vectors.'","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:17:28.276122-05:00","updated_at":"2025-12-20T20:18:36.111869-05:00","closed_at":"2025-12-20T20:18:36.111869-05:00","close_reason":"Closed"}
{"id":"babygpt-j5q","title":"2.4 Gap: Circular reasoning on coordinates","description":"Line ~444-445: 'Coordinates make sense because of statistical relationships' — but this is circular. We ASSERT embeddings should exist because stats are countable. WHY do countable stats = valid coordinates? FIX: Add the missing step: coordinates are valid if operations on them (add, scale, dot) correspond to meaningful operations on the original objects. Stats form a vector space (can add, scale). That's the justification.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:49:51.738121-05:00","updated_at":"2025-12-20T21:38:06.397128-05:00","closed_at":"2025-12-20T21:38:06.397128-05:00","close_reason":"Fixed: replaced vague 'vector operations mirror statistical operations' with concrete example - averaging 'a' and 'e' vectors gives high value in followed-by-n slot because both precede n"}
{"id":"babygpt-j6l","title":"3.13 Audit 1.3.2 Free Lunch dependencies","description":"AUDIT: Read section 1.3.2, verify causal masking 'looking right is forbidden' is adequately motivated. IF unclear why: add 'you can't know the future when predicting' callout.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:13:55.221605-05:00","updated_at":"2025-12-20T19:42:29.111412-05:00","closed_at":"2025-12-20T19:42:29.111412-05:00","close_reason":"Closed"}
{"id":"babygpt-k85","title":"1.1.7.1 Gap: Backoff mathematical justification","description":"Line ~1064: Backoff introduced with ladder metaphor but mathematical mechanism missing. WHY is shortening context valid? FIX: Add explanation: if P('sat'|'the cat') is undefined (zero count), we ASSUME it's similar to P('sat'|'cat') or even P('sat'). This is the smoothing assumption — shorter contexts are less precise but non-zero. We trade accuracy for coverage.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:48:48.40969-05:00","updated_at":"2025-12-20T21:17:05.959569-05:00","closed_at":"2025-12-20T21:17:05.959569-05:00","close_reason":"FIXED: Added backoff ladder explanation + made limit precise: 'the cat sat' and 'the dog sat' remain separate keys, sharing requires exact substring match"}
{"id":"babygpt-kcu","title":"2.2 Gap: HOW modeling tokens solves reuse","description":"Line ~306-309: 'Stop memorizing contexts, start modeling tokens' — but HOW does this solve reuse? Claim stated, not derived. FIX: Add derivation: if 'cat' and 'dog' have similar embeddings, then contexts containing them produce similar predictions. One learned embedding serves ALL contexts containing that token. V embeddings serve V^T contexts. That's the compression: V \u003c\u003c V^T.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:49:19.739476-05:00","updated_at":"2025-12-20T21:28:49.181037-05:00","closed_at":"2025-12-20T21:28:49.181037-05:00","close_reason":"FIXED: Added derivation showing compression math (V embeddings serve V^T contexts). One embedding for 'cat' serves all contexts containing it. Concrete example: vocab 27, T=3 → 19,683 entries vs 27. Claim now derived from first principles."}
{"id":"babygpt-kic","title":"PHASE 7: Difficulty Curve","description":"Audit difficulty spikes and transitions (5 issues)","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-20T19:10:59.794166-05:00","updated_at":"2025-12-20T20:30:35.430159-05:00","closed_at":"2025-12-20T20:30:35.430159-05:00","close_reason":"Difficulty curve audit complete. All issues passed. Collapsibles used appropriately for math spikes."}
{"id":"babygpt-kks","title":"PHASE 3: Ch1 Dependency Audit","description":"Audit conceptual dependencies for each Chapter 1 section (15 issues)","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-20T19:10:58.613251-05:00","updated_at":"2025-12-20T20:30:21.076498-05:00","closed_at":"2025-12-20T20:30:21.076498-05:00","close_reason":"Ch1 dependency audit complete. 36/37 issues passed. Fixed: perplexity definition added before first use."}
{"id":"babygpt-kmd","title":"8.2 Gap audit: dot product","description":"AUDIT: Find first usage of dot product, verify definition precedes it. IF gap: create ticket to add conceptual intro before formula.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:16:46.23742-05:00","updated_at":"2025-12-20T20:09:28.205004-05:00","closed_at":"2025-12-20T20:09:28.205004-05:00","close_reason":"Closed"}
{"id":"babygpt-ko7","title":"PHASE 4: Ch2 Dependency Audit","description":"Audit conceptual dependencies for each Chapter 2 section (11 issues)","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-20T19:10:58.911021-05:00","updated_at":"2025-12-20T20:30:21.969548-05:00","closed_at":"2025-12-20T20:30:21.969548-05:00","close_reason":"Ch2 dependency audit complete. Fixed: SectionLinks corrected, Ch1 reference added in 2.3."}
{"id":"babygpt-kp5","title":"Softmax: Elevate from standard to exceptional","description":"Unique insight: Softmax is the ONLY answer to 'least-biased distribution given scores' (max entropy theorem). Add: (1) 'Why exp?' callout explaining inevitability, (2) SoftmaxSimplexViz showing 3-logit sliders → point on triangle, (3) Boltzmann connection as optional collapsible, (4) gradient cancellation explanation.","status":"closed","issue_type":"feature","created_at":"2025-12-20T22:13:13.034021-05:00","updated_at":"2025-12-20T22:25:16.177739-05:00","closed_at":"2025-12-20T22:25:16.177739-05:00","close_reason":"Implemented SoftmaxSimplexViz with probability triangle + temperature, added max-entropy callout (why exp is ONLY answer), gradient callout, and Boltzmann physics connection. Accessible and democratic."}
{"id":"babygpt-kua","title":"Extract StepDots reusable component (step indicator pattern)","description":"Extract the repeated step indicator UI (dots, active state, click handlers) into a StepDots component and migrate call sites.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-20T23:38:24.591116-05:00","updated_at":"2025-12-20T23:40:34.461466-05:00"}
{"id":"babygpt-lfn","title":"4.8 Audit 2.8 Tensors dependencies","description":"AUDIT: Read section 2.8, verify it requires embedding lookup from 2.5. Check [B,T,D] notation has adequate context. IF shape notation unclear: add dimension explanation table.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:14:22.541482-05:00","updated_at":"2025-12-20T19:55:05.509377-05:00","closed_at":"2025-12-20T19:55:05.509377-05:00","close_reason":"Closed"}
{"id":"babygpt-lgn","title":"Extract VizCard reusable component (header + content + footer pattern from 11 vizzes)","description":"Create src/components/VizCard.tsx + VizCard.module.css to unify the common viz wrapper: ambient glow container, glass card, header (title + optional figNum/subtitle), content slot, optional footer. Export from src/components/index.ts and refactor initial viz components to use it.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T23:38:22.055457-05:00","updated_at":"2025-12-21T00:24:44.23236-05:00","closed_at":"2025-12-21T00:24:44.23236-05:00","close_reason":"Added VizCard component and migrated key vizzes"}
{"id":"babygpt-lhx","title":"1.1.5 Gap: What Markov assumption loses","description":"Line ~489-495: Markov Assumption introduced as solution to sparsity, but doesn't explain what we're LOSING. FIX: Add concrete example of information death. E.g., 'The doctor said she would...' — with n=2, we only see 'would' and lose 'doctor' and 'she'. Gender agreement, long-range coherence, topic — all die. This is WHY we eventually need attention.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:48:17.217057-05:00","updated_at":"2025-12-20T21:06:49.151068-05:00","closed_at":"2025-12-20T21:06:49.151068-05:00","close_reason":"FIXED: Added concrete example showing information loss from Markov truncation - 'The doctor said she would...' example demonstrates loss of gender agreement, professional roles, and topic when context window is too small"}
{"id":"babygpt-lwe","title":"4.6 Audit 2.6 Dot Product dependencies","description":"AUDIT: Read section 2.6, verify it requires fingerprint from 2.3. Check SectionLink to 2.1 Grassmann is accurate. IF inaccurate: fix link or description.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:14:21.962273-05:00","updated_at":"2025-12-20T19:53:40.269015-05:00","closed_at":"2025-12-20T19:53:40.269015-05:00","close_reason":"Closed"}
{"id":"babygpt-m4l","title":"6.3 Terminology audit: embedding vs vector","description":"AUDIT: check first usage establishes relationship. IF ambiguous: add definition where 'embedding' first appears. Create ticket to add term to glossary if none exists.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:16:11.362548-05:00","updated_at":"2025-12-20T20:29:38.77957-05:00","closed_at":"2025-12-20T20:29:38.77957-05:00","close_reason":"PASS: Relationship established in Ch2 Section 2.4 'Vectors Are Just Storage' - vectors store attributes, embeddings are learned vectors for tokens."}
{"id":"babygpt-mcb","title":"CSS: Add spacing scale tokens to replace ad-hoc values","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T23:18:15.095696-05:00","updated_at":"2025-12-20T23:31:50.097453-05:00","closed_at":"2025-12-20T23:31:50.097453-05:00","close_reason":"Closed"}
{"id":"babygpt-miu","title":"1.8 Validate Ch2 map waypoint 2.1 Grassmann","description":"AUDIT: Navigate to 2.1 via waypoint, verify 'colors to language' description matches Grassmann section. IF mismatch: update description to reflect actual historical narrative focus.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:11:37.19632-05:00","updated_at":"2025-12-20T19:31:16.181193-05:00","closed_at":"2025-12-20T19:31:16.181193-05:00","close_reason":"Closed"}
{"id":"babygpt-mw5","title":"PHASE 1: ChapterMap Validation","description":"Validate all ChapterMap waypoints link correctly and descriptions match content (14 issues)","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-20T19:10:48.567941-05:00","updated_at":"2025-12-20T20:30:19.252676-05:00","closed_at":"2025-12-20T20:30:19.252676-05:00","close_reason":"All ChapterMap validation issues resolved. Fixed: Ch2 title mismatch (Handoff→Nudge), added missing waypoints (2.5, 2.7, 2.8, 2.9)."}
{"id":"babygpt-n36","title":"10.2 Transition audit: 1.1.8-\u003e1.2","description":"AUDIT: Check bridge from chain rule application to 'let's build the tokenizer'. IF abrupt: create ticket to add transition like 'Theory in hand, time to build.'","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:17:27.382782-05:00","updated_at":"2025-12-20T19:53:45.624286-05:00","closed_at":"2025-12-20T19:53:45.624286-05:00","close_reason":"Closed"}
{"id":"babygpt-n3z","title":"2.14 Validate Ch2 invariant: Training nudges based on error","description":"AUDIT: Read section 2.10, verify training loop mechanism is clear (predict, measure error, nudge). IF missing: add diagram or pseudo-code. IF unclear: add step-by-step walkthrough.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:12:21.091193-05:00","updated_at":"2025-12-20T19:48:21.392133-05:00","closed_at":"2025-12-20T19:48:21.392133-05:00","close_reason":"Closed"}
{"id":"babygpt-n6b","title":"Chain Rule: Add Jurafsky-Martin level formal rigor","description":"FormalRigor component: Collapsible with 'Formal' badge. Content: (1) P(B|A) definition → chain rule identity, (2) induction to n, (3) P(context)=0 edge case (formal smoothing motivation), (4) probability space Omega/F/P, (5) optional measure theory hook. Each part connects back to corridor intuition.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-12-20T22:13:14.680484-05:00","updated_at":"2025-12-20T22:21:24.652277-05:00","closed_at":"2025-12-20T22:21:24.652277-05:00","close_reason":"FormalRigor component implemented with accessible, democratic tone"}
{"id":"babygpt-p78","title":"5.3 Validate SectionLink in 2.6 to 2.1","description":"AUDIT: Line 718 in Ch2, find SectionLink to 2.1. Verify Grassmann backward reference accurately reflects 2.1 content. IF inaccurate: update link text to match.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:14:39.923788-05:00","updated_at":"2025-12-20T20:01:39.580451-05:00","closed_at":"2025-12-20T20:01:39.580451-05:00","close_reason":"Closed"}
{"id":"babygpt-pqb","title":"3.14 Audit 1.6 The Limit dependencies","description":"AUDIT: Read section 1.6, verify it summarizes sparsity limit and properly sets up Ch2. IF Ch2 not foreshadowed: add explicit 'next chapter will...' statement. IF sparsity not summarized: add recap.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:13:55.507254-05:00","updated_at":"2025-12-20T19:42:29.404919-05:00","closed_at":"2025-12-20T19:42:29.404919-05:00","close_reason":"Closed"}
{"id":"babygpt-q4t","title":"2.4 Gap: Proper nouns vs adjectives conflation","description":"Line ~428-438: The metaphor conflates two claims: (1) integers are just labels, (2) vectors enable learning. These aren't the same. WHY can't labels learn? FIX: Separate the claims. Labels can't learn because they have no shared structure. 'cat'=17, 'dog'=42 — there's no operation that moves 17 toward 42. Vectors CAN be nudged: v_cat += 0.01 * gradient. Continuous space enables gradient descent.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:49:43.994118-05:00","updated_at":"2025-12-20T21:32:51.782488-05:00","closed_at":"2025-12-20T21:32:51.782488-05:00","close_reason":"FIXED: Added gradient descent mechanism - integers can't learn because no operation moves 17 toward 42; vectors enable v += 0.01*gradient in continuous space"}
{"id":"babygpt-qh0","title":"4.5 Audit 2.5 Embedding Lookup dependencies","description":"AUDIT: Read section 2.5, verify it requires embedding table concept from 2.4. Check row selection mechanics are adequately motivated. IF unclear: add visual or SectionLink.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:14:21.678121-05:00","updated_at":"2025-12-20T19:52:55.44936-05:00","closed_at":"2025-12-20T19:52:55.44936-05:00","close_reason":"Closed"}
{"id":"babygpt-r1p","title":"4.10 KNOWN: Audit 2.10 loss function introduction","description":"KNOWN ISSUE: Cross-entropy loss may not be formally defined until this section. Check earlier loss refs","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T19:14:23.130719-05:00","updated_at":"2025-12-20T20:00:33.591449-05:00","closed_at":"2025-12-20T20:00:33.591449-05:00","close_reason":"Closed"}
{"id":"babygpt-r88","title":"2.2 Gap: WHY can't lookup tables generalize","description":"Line ~288: n-grams called 'islands' but WHY can't hash tables generalize? They can store ANY context... FIX: Add explanation: hash tables map keys to values with no notion of 'nearby keys'. Hash('dog sat') and Hash('cat sat') are unrelated integers. To generalize, you need GEOMETRY — a space where similar inputs are nearby. Hash tables have no geometry. This is the fundamental limit.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:49:12.40026-05:00","updated_at":"2025-12-20T21:27:27.23295-05:00","closed_at":"2025-12-20T21:27:27.23295-05:00","close_reason":"FIXED: Added concrete explanation of hash table mechanism - hash functions map strings to unrelated integers (addresses/slots), not coordinates in a space. Change one letter and the hash jumps to a completely different memory location. No notion of distance built into the data structure."}
{"id":"babygpt-rd9","title":"1.11 Validate Ch2 map waypoint 2.4 Embedding Table","description":"AUDIT: Navigate to 2.4, verify 'D numbers per token' description matches 'Vectors Are Just Storage'. IF mismatch: update to reflect actual content.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:11:38.116683-05:00","updated_at":"2025-12-20T19:33:16.527827-05:00","closed_at":"2025-12-20T19:33:16.527827-05:00","close_reason":"Closed"}
{"id":"babygpt-res","title":"CodeWalkthrough: Polish sweep","description":"Sweep CodeWalkthrough for:\n- Theme consistency (colors, fonts, spacing)\n- Visual polish (code highlighting, step transitions)\n- Accessibility (aria labels, keyboard nav)\n- Mobile responsiveness\n\nReference gold standards:\n- GradientDescentViz (ambient glow, step interaction)\n- CrossEntropyViz (dynamic value display)\n- DotProductViz (panel layouts)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T22:57:34.641723-05:00","updated_at":"2025-12-20T23:01:57.716875-05:00","closed_at":"2025-12-20T23:01:57.716875-05:00","close_reason":"Polish sweep complete: ambient glow, multi-gradient backgrounds, header structure, transitions, hover states, mobile responsive breakpoints, ARIA labels"}
{"id":"babygpt-sbz","title":"6.6 Terminology audit: context_length vs block_size vs T","description":"AUDIT: find all three terms. IF not explicitly connected: add callout 'These three names mean the same thing: context_length, block_size, and T all refer to...'. Create ticket for fix.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:16:12.210875-05:00","updated_at":"2025-12-20T20:29:54.015098-05:00","closed_at":"2025-12-20T20:29:54.015098-05:00","close_reason":"PASS: T used consistently for context length. block_size only appears in code context. context_length explained in prose. Equivalence clear in Section 2.8."}
{"id":"babygpt-scr","title":"CSS: Create shared hover/focus state utilities","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T23:18:18.33111-05:00","updated_at":"2025-12-20T23:33:21.099617-05:00","closed_at":"2025-12-20T23:33:21.099617-05:00","close_reason":"Closed"}
{"id":"babygpt-sgx","title":"3.7 Audit 1.1.6 Building From Corpus dependencies","description":"AUDIT: Read section 1.1.6, verify it requires chain rule (1.1.5) and builds concrete counting examples. IF chain rule not referenced: add SectionLink. IF counting unclear: add FrequencyTable example.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:13:33.003599-05:00","updated_at":"2025-12-20T19:42:02.066115-05:00","closed_at":"2025-12-20T19:42:02.066115-05:00","close_reason":"Closed"}
{"id":"babygpt-sh2","title":"Restore misc missing sections","description":"Add: Sampling: Let It Talk, From Surprise to Loss, The Math: Chain Rule, Build a toy model, Build the pipeline, Define the goal, Hit the limit, What comes next, Pick the biggest term in the sum, Retrain on the current chapter corpus","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T18:34:15.938805-05:00","updated_at":"2025-12-20T18:49:01.787359-05:00","closed_at":"2025-12-20T18:49:01.787359-05:00","close_reason":"Closed","comments":[{"id":2,"issue_id":"babygpt-sh2","author":"andrewlouis","text":"Added: A Running Mini-Corpus, Telescoping With The Same Example, We Just Built a Markov Chain, What Chapter 1 Can't Do (Yet)","created_at":"2025-12-20T23:38:37Z"},{"id":3,"issue_id":"babygpt-sh2","author":"andrewlouis","text":"Verified: The Math: Chain Rule content already exists (Geometric Intuition callout + corridor metaphor)","created_at":"2025-12-20T23:39:04Z"},{"id":8,"issue_id":"babygpt-sh2","author":"andrewlouis","text":"Final status: Sampling: Let It Talk ADDED, From Surprise to Loss ADDED (previous session), The Math: Chain Rule exists as 'The Chain Rule', Build a toy model/Build the pipeline/Define the goal/Hit the limit are ChapterMap entries not content sections, What comes next exists as 'What's Next', Pick the biggest term is a button label, Retrain on corpus is a toggle label. All content verified present.","created_at":"2025-12-20T23:48:59Z"}]}
{"id":"babygpt-sly","title":"GradientTraceDemo: Polish sweep","description":"Sweep GradientTraceDemo for:\n- Theme consistency (colors, fonts, spacing match existing vizzes)\n- Visual polish (code highlighting, step transitions, output formatting)\n- Accessibility (aria labels, keyboard nav for step buttons)\n- Mobile responsiveness (two-panel layout on small screens)\n\nGold standards to reference:\n- GradientDescentViz (ambient glow, step-by-step interaction)\n- CrossEntropyViz (dynamic value display)\n- CodeWalkthrough (code panel styling, step highlighting)\n- NeuralTrainingDemo (training step visualization)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T22:52:31.766306-05:00","updated_at":"2025-12-20T23:13:41.555954-05:00","closed_at":"2025-12-20T23:13:41.555954-05:00","close_reason":"Closed"}
{"id":"babygpt-t4d","title":"10.4 Transition audit: Ch1-\u003eCh2","description":"AUDIT: Check ChapterNav + Section 1.7 adequately prepare reader for Ch2's philosophical style (Grassmann history). IF gap: create ticket to adjust 1.7 ending or add Ch2 preamble.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:17:27.97311-05:00","updated_at":"2025-12-20T20:16:39.15769-05:00","closed_at":"2025-12-20T20:16:39.15769-05:00","close_reason":"Closed"}
{"id":"babygpt-t50","title":"GeometricDotProductViz: Polish sweep","description":"Sweep GeometricDotProductViz for:\n- Theme consistency (colors, fonts, spacing match existing vizzes)\n- Visual polish (gradients, transitions, hover states)\n- Accessibility (aria labels, keyboard nav)\n- Mobile responsiveness\n\nGold standards to reference:\n- GradientDescentViz (ambient glow, formula display, step interaction)\n- CrossEntropyViz (curve rendering, guide lines, axis labels)\n- CodeWalkthrough (panel layouts)\n- NeuralTrainingDemo (interactive training viz)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T22:52:29.993735-05:00","updated_at":"2025-12-20T23:06:35.831951-05:00","closed_at":"2025-12-20T23:06:35.831951-05:00","close_reason":"Polish sweep complete: vector gradients, keyboard nav (arrow keys + shift), touch support, ARIA labels, cubic-bezier transitions, focus states, mobile responsive, theme-consistent rgba colors"}
{"id":"babygpt-t74","title":"3.9 Audit 1.1.7.2 Sparsity Trap dependencies","description":"AUDIT: Read section 1.1.7.2, verify it builds on counting from 1.1.6. Check zero-probability problem is clearly introduced before cross-entropy formula. IF gap: add bridging explanation.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:13:54.089992-05:00","updated_at":"2025-12-20T19:42:28.227795-05:00","closed_at":"2025-12-20T19:42:28.227795-05:00","close_reason":"Closed"}
{"id":"babygpt-tfi","title":"CSS: Add breakpoint tokens (currently hardcoded 600/700/768px)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T23:18:19.989928-05:00","updated_at":"2025-12-20T23:34:13.078193-05:00","closed_at":"2025-12-20T23:34:13.078193-05:00","close_reason":"Closed"}
{"id":"babygpt-tk7","title":"5.5 Audit implicit Ch2-\u003eCh1 references","description":"AUDIT: Search Ch2 for Ch1 concept reuse (P(next|c), tokenization, chain rule). Check if proper backward refs exist when reusing. IF no refs: add 'As established in Chapter 1...' callouts where appropriate.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:14:40.517066-05:00","updated_at":"2025-12-20T20:04:39.341073-05:00","closed_at":"2025-12-20T20:04:39.341073-05:00","close_reason":"Closed"}
{"id":"babygpt-tps","title":"8.7 KNOWN: Gap audit dot product-\u003eprobability","description":"KNOWN ISSUE: Connection between dot product and probability (via softmax) may not be foreshadowed in Ch1. AUDIT: check if Ch1 probability discussion sets up Ch2 dot product. IF gap: create ticket to add foreshadowing callout in Ch1.6.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T19:16:47.6341-05:00","updated_at":"2025-12-20T20:14:40.922591-05:00","closed_at":"2025-12-20T20:14:40.922591-05:00","close_reason":"Closed"}
{"id":"babygpt-u2a","title":"7.1 Difficulty audit: KenLM section 1.1.7.1","description":"AUDIT: Compare abstraction level (hashing, linear probing, pointer math) vs surrounding sections. IF spike: create ticket to move to appendix OR add 'optional deep dive' collapsible wrapper.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:16:28.330005-05:00","updated_at":"2025-12-20T19:44:55.839345-05:00","closed_at":"2025-12-20T19:44:55.839345-05:00","close_reason":"Closed"}
{"id":"babygpt-ud2","title":"PHASE 10: Missing Transitions","description":"Find abrupt section transitions (6 issues)","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-20T19:11:00.667977-05:00","updated_at":"2025-12-20T20:30:45.499015-05:00","closed_at":"2025-12-20T20:30:45.499015-05:00","close_reason":"Missing transitions audit complete. All 6 issues passed. Transition prose exists between major sections."}
{"id":"babygpt-ujl","title":"8.1 KNOWN: Gap audit cross-entropy","description":"KNOWN ISSUE: Cross-entropy formula in 1.1.7.2 Sparsity Trap but may not be formally defined until Ch2. AUDIT: trace first usage vs first definition. IF gap: create ticket to add definition before first use OR add forward-ref callout.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-20T19:16:45.94936-05:00","updated_at":"2025-12-20T19:48:40.747249-05:00","closed_at":"2025-12-20T19:48:40.747249-05:00","close_reason":"Closed"}
{"id":"babygpt-upu","title":"1.2 Gap: Why character-level helps connectivity","description":"Line ~540: 'Word graph is disconnected' stated but no explanation of WHY character-level helps. Space char as 'bridge' mentioned but mechanism unclear. FIX: Add explanation: at word level, 'cat' and 'dog' share zero characters. At char level, both contain common suffixes/patterns. Space char appears after EVERY word, creating a hub node. Character-level has inherent overlap that word-level lacks.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:48:24.292738-05:00","updated_at":"2025-12-20T21:08:05.551959-05:00","closed_at":"2025-12-20T21:08:05.551959-05:00","close_reason":"FIXED: Added concrete explanation of why character-level helps with sparsity. Explained that word-level 'cat' and 'dog' share zero structure, while character-level reveals overlap (consonant endings, CVC patterns). Crucially explained that space character creates a universal hub node with stable statistics from high frequency, enabling recombination of any word-ending with any word-beginning."}
{"id":"babygpt-vcq","title":"1.5 Validate Ch1 map waypoint 1.6 The Limit","description":"AUDIT: Navigate to 1.6, verify description about scaling limits. IF mismatch: update. Check if section clearly establishes why memorization doesn't scale.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:11:24.024794-05:00","updated_at":"2025-12-20T19:31:19.565161-05:00","closed_at":"2025-12-20T19:31:19.565161-05:00","close_reason":"Closed"}
{"id":"babygpt-veo","title":"1.10 Validate Ch2 map waypoint 2.3 Ground Truth","description":"AUDIT: Navigate to 2.3, verify similarity definition description matches 'What Can We Measure?' section. IF mismatch: update. Ensure description captures P(next|c) fingerprint concept.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:11:37.819215-05:00","updated_at":"2025-12-20T19:32:34.288948-05:00","closed_at":"2025-12-20T19:32:34.288948-05:00","close_reason":"Closed"}
{"id":"babygpt-vp6","title":"1.1 Validate Ch1 map waypoint 1.1 The Physics","description":"AUDIT: Navigate to section 1.1 via waypoint, verify anchor works. Check description 'What we are predicting, why probability is the whole game' matches section content. IF broken link: fix section ID. IF description mismatch: update ChapterMap description.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:11:22.858935-05:00","updated_at":"2025-12-20T19:31:18.438925-05:00","closed_at":"2025-12-20T19:31:18.438925-05:00","close_reason":"Closed"}
{"id":"babygpt-w7e","title":"2.7 Validate Ch2 invariant: Token IDs are arbitrary labels","description":"AUDIT: Read section 2.4, verify 'token IDs are arbitrary labels with no meaningful distance' is explicit. IF missing: create ticket to add Integer Distance Lie callout. IF implicit: make explicit.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:12:19.057044-05:00","updated_at":"2025-12-20T19:42:02.475425-05:00","closed_at":"2025-12-20T19:42:02.475425-05:00","close_reason":"Closed"}
{"id":"babygpt-wcf","title":"4.2 Audit 2.2 Reuse Question dependencies","description":"AUDIT: Read section 2.2, verify it requires Ch1 n-gram concept. Check 'the cat' vs 'a cat' example refs counting model limits. IF no Ch1 connection: add explicit backward ref.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:14:20.811776-05:00","updated_at":"2025-12-20T19:50:14.742609-05:00","closed_at":"2025-12-20T19:50:14.742609-05:00","close_reason":"Closed"}
{"id":"babygpt-wk3","title":"1.1.1 Gap: Why independence matters for language modeling","description":"Line ~205: 'Surprise should be additive' is stated but WHY independence matters for text prediction isn't explained. The jump from 'two coins' to language is unmotivated. FIX: Add 1-2 sentences explaining that text characters ARE approximately independent given context, so additive surprise lets us score sequences by summing character-level surprises.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:47:26.503652-05:00","updated_at":"2025-12-20T20:52:03.052046-05:00","closed_at":"2025-12-20T20:52:03.052046-05:00","close_reason":"FIXED: Added explanatory bridge between 'additive surprise' and language modeling - explained that text characters are approximately independent given context, enabling sequence scoring via summed per-character surprises"}
{"id":"babygpt-wss","title":"7.3 Difficulty audit: Gradient derivation 2.10","description":"AUDIT: Check if calculus-based gradient derivation has adequate collapsible/optional wrappers. IF naked math: create ticket to wrap in expandable section with 'skip if not interested in math' note.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:16:28.913342-05:00","updated_at":"2025-12-20T20:06:54.898417-05:00","closed_at":"2025-12-20T20:06:54.898417-05:00","close_reason":"Closed"}
{"id":"babygpt-x1s","title":"CSS: Replace 28 hardcoded font-family with var(--font-*) (8 files)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T23:18:09.39879-05:00","updated_at":"2025-12-20T23:27:46.032006-05:00","closed_at":"2025-12-20T23:27:46.032006-05:00","close_reason":"Closed"}
{"id":"babygpt-x8o","title":"1.1.3 Gap: Derive 27^T explicitly","description":"Line ~407-408: The warehouse metaphor is vivid but 27^T isn't derived. WHERE does the exponent come from? FIX: Add explicit derivation: T positions × V choices per position = V^T total contexts. For V=27, T=5: 27^5 = 14,348,907. Show the combinatorial explosion as a concrete calculation, not just a claim.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T20:48:00.617686-05:00","updated_at":"2025-12-20T21:02:30.91003-05:00","closed_at":"2025-12-20T21:02:30.91003-05:00","close_reason":"FIXED: Deleted redundant paragraph. Extended MathBlock explanation with 'Multiplication, not addition — because each choice at position 1 can pair with any of 27 at position 2.'"}
{"id":"babygpt-y3f","title":"7.2 Difficulty audit: Ch1-\u003eCh2 transition","description":"AUDIT: Compare difficulty at end of Ch1 vs start of Ch2 (Grassmann history). IF gap: create ticket to add bridging paragraph or adjust Ch1 ending tone.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:16:28.61759-05:00","updated_at":"2025-12-20T20:05:47.258521-05:00","closed_at":"2025-12-20T20:05:47.258521-05:00","close_reason":"Closed"}
{"id":"babygpt-ygf","title":"8.4 Gap audit: softmax","description":"AUDIT: Verify softmax not referenced before Section 2.7 definition. IF early reference found: create ticket to relocate or add forward-ref.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:16:46.79527-05:00","updated_at":"2025-12-20T20:12:43.20592-05:00","closed_at":"2025-12-20T20:12:43.20592-05:00","close_reason":"Closed"}
{"id":"babygpt-z4x","title":"3.2 Audit 1.1.1 What Is Probability dependencies","description":"AUDIT: Read section 1.1.1, verify surprise=-log2(p) is defined BEFORE any cross-entropy reference. IF cross-entropy appears first: create ticket to reorder or add surprise definition earlier.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:13:31.587934-05:00","updated_at":"2025-12-20T19:42:00.562455-05:00","closed_at":"2025-12-20T19:42:00.562455-05:00","close_reason":"Closed"}
{"id":"babygpt-zd1","title":"3.11 Audit 1.2 Tokenization dependencies","description":"AUDIT: Read section 1.2, verify proper transition from theory to implementation. Check if chars-vs-words choice is motivated by sparsity discussion. IF not connected: add SectionLink to 1.1.7.2.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:13:54.65702-05:00","updated_at":"2025-12-20T19:42:28.510479-05:00","closed_at":"2025-12-20T19:42:28.510479-05:00","close_reason":"Closed"}
{"id":"babygpt-zdb","title":"6.4 Terminology audit: loss vs surprise vs cross-entropy","description":"AUDIT: trace where each term first appears and if relationship is explained. IF gap: add callout establishing 'surprise = -log(p), loss = average surprise, cross-entropy = expected surprise'. Create remediation ticket.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:16:11.642076-05:00","updated_at":"2025-12-20T20:29:39.652984-05:00","closed_at":"2025-12-20T20:29:39.652984-05:00","close_reason":"PASS: Relationship established in Ch2: surprise=-log(p), loss=cross-entropy=average surprise, defined at line 1037 and 2.10 sections."}
{"id":"babygpt-zmt","title":"CSS: Replace 100 hardcoded hex colors with CSS variables (19 files)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T23:18:08.49681-05:00","updated_at":"2025-12-20T23:25:25.33739-05:00","closed_at":"2025-12-20T23:25:25.33739-05:00","close_reason":"Closed"}
{"id":"babygpt-zww","title":"2.1 Validate Ch1 invariant: P(next|context) via chain rule","description":"AUDIT: Read Invariants component in Ch1, verify claim 'P(next|context) via chain rule'. Trace sections 1.1.5 + earlier to confirm derivation exists. IF missing: create ticket to add derivation. IF present but unclear: create ticket to clarify.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-20T19:11:59.990794-05:00","updated_at":"2025-12-20T19:32:32.044197-05:00","closed_at":"2025-12-20T19:32:32.044197-05:00","close_reason":"Closed"}
